{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from torchvision.transforms.functional import to_pil_image, to_tensor\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "\n",
    "from train_scripts.cocodata import COCOInstancesDataset\n",
    "from llavacaption import Captioner, add_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadedmodels = None\n",
    "dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loadedmodels is None:\n",
    "    loadedmodels = Captioner(mistralmodel=None).get_loadedmodels()\n",
    "captioner = Captioner(loadedmodels=loadedmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset is None:\n",
    "    dataset = COCOInstancesDataset(maindir=\"/USERSPACE/lukovdg1/coco2017\", split=\"val\", upscale_to=512, max_masks=21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eids = [78,79,80] #+[500, 501, 502] #+ [1010, 1011, 1012, 1013] #+ [1005, 1006, 1007, 1008] #+ [1002, 1004, 0, 100, 1001, 50]\n",
    "for eid in eids:\n",
    "    example = dataset.examples[eid]\n",
    "    print(example.id, example.captions)\n",
    "    img = example.load_image()\n",
    "    display(img)\n",
    "    print(\"adding descriptions\")\n",
    "    example = add_descriptions(example, captioner)\n",
    "    print(\"added descriptions\")\n",
    "    for seg in example.seg_info:\n",
    "        x, y, xx, yy = seg[\"bbox\"]\n",
    "        cropped = img.crop([x, y, x + xx, y + yy])\n",
    "        print(seg[\"category_name\"], \", \", seg[\"description\"])\n",
    "        display(cropped)\n",
    "        # print(seg[\"category_name\"], (xx * yy), (xx, yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
